{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP 입문.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP239npy/gpEjOixp0Smamw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"R6o5NTSesQVK","executionInfo":{"status":"ok","timestamp":1637811056280,"user_tz":-540,"elapsed":2964,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}}},"source":["import tensorflow as tf\n","tf.__version__\n","import keras\n","keras.__version__\n","import gensim\n","gensim.__version__\n","import sklearn\n","sklearn.__version__\n","# nltk 임포트\n","import nltk\n","nltk.__version__"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wI_ATwviJUy-"},"source":["#  \"드라이브 마운트\" > \"디렉토리 이동\" > \"임포트\" "]},{"cell_type":"markdown","metadata":{"id":"39zjl-xOKR8R"},"source":["### 드라이브 이동"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NzMjox4bLDgo","executionInfo":{"status":"ok","timestamp":1637811531301,"user_tz":-540,"elapsed":26768,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"ec33eac4-fde9-4554-90b6-449523e2bd1d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMfVcLqLLLll","executionInfo":{"status":"ok","timestamp":1637812079679,"user_tz":-540,"elapsed":17,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"8190c404-0f5f-4213-b06e-66e52862898b"},"source":["!pwd"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-qzMVOBKbsN","executionInfo":{"status":"ok","timestamp":1637812611640,"user_tz":-540,"elapsed":430,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"9f673ccb-1fd2-49c9-e113-02f442a6e37d"},"source":["# %cd [프로젝트 위치]\n","%cd /content/drive/MyDrive/project "],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/project\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUwb4syiK6kw","executionInfo":{"status":"ok","timestamp":1637812624901,"user_tz":-540,"elapsed":479,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"2b09e773-57b0-4af8-f44d-fa5d27ee6f7e"},"source":["!ls"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["colab_code  dataset  module\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"o8I9LaY5Lzz5","executionInfo":{"status":"ok","timestamp":1637812280475,"user_tz":-540,"elapsed":536,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"95275110-3451-41cf-a6c3-af4add037f69"},"source":["import os\n","os.getcwd()"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"H-3gN7C9OBhK"},"source":["pip install konlpy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"yYMHrOk8P7l_","executionInfo":{"status":"ok","timestamp":1637812869261,"user_tz":-540,"elapsed":617,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"a352ca0d-770a-4714-a33c-718cf7679984"},"source":["import konlpy\n","konlpy.__version__"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.5.2'"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"gi6L5caZQRHr"},"source":["# 판다스, 넘파이, 맷플롯립"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-HtRgAnTQYZK","executionInfo":{"status":"ok","timestamp":1637812965830,"user_tz":-540,"elapsed":508,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"338c6da8-2317-4880-aaa0-9a09270b4dc6"},"source":["import pandas as pd \n","import numpy as np \n","import matplotlib\n","\n","print(pd.__version__ )\n","print(np.__version__ )\n","print(matplotlib.__version__)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["1.1.5\n","1.19.5\n","3.2.2\n"]}]},{"cell_type":"markdown","metadata":{"id":"2h7lA4KrQfio"},"source":["### 넘파이의 주요 기능"]},{"cell_type":"markdown","metadata":{"id":"DAhaMvJHRQ_a"},"source":["1. np.array() # 리스트, 튜플, 배열로 부터 ndarray를 생성\n","2. np.asarray() # 기존의 array로 부터 ndarray를 생성\n","3. np.arange() # range와 비슷\n","4. np.linspace(start, end, num) # [start, end] 균일한 간격으로 num개 생성\n","5. np.logspace(start, end, num) # [start, end] log scale 간격으로 num개 생성"]},{"cell_type":"markdown","metadata":{"id":"JWZTff4pRhtJ"},"source":["1) np.array\n","- Numpy 의 핵심은 ndarray , np.array() 는 리스트, 튜플, 배열로 부터 ndarray를 생성합니다. 또한 인덱스가 0부터 시작"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bLyzvc7jRhvx","executionInfo":{"status":"ok","timestamp":1637813319624,"user_tz":-540,"elapsed":507,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"708c063c-eab8-4c0c-adcd-54c3643ca334"},"source":["a = np.array([1, 2, 3, 4, 5]) #리스트를 가지고 1차원 배열 생성\n","print(type(a))\n","print(a)"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","[1 2 3 4 5]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbO0kTOHRhyj","executionInfo":{"status":"ok","timestamp":1637813332244,"user_tz":-540,"elapsed":521,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"fc127fa9-7ed6-4cc8-a3ad-5adad0310a45"},"source":["b = np.array([[10, 20, 30], [ 60, 70, 80]]) \n","print(b) #출력"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["[[10 20 30]\n"," [60 70 80]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmPhRylHRh05","executionInfo":{"status":"ok","timestamp":1637813340934,"user_tz":-540,"elapsed":522,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"0c9bf48d-5786-4432-e246-c7e9d97b6e94"},"source":["print(b.ndim) #차원 출력 # 2차원 : 행렬\n","print(b.shape) #크기 출력 "],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","(2, 3)\n"]}]},{"cell_type":"markdown","metadata":{"id":"At3zMpdURh3K"},"source":["2) ndarray의 초기화\n","- 위에서는 리스트를 가지고 ndarray를 생성했지만, ndarray를 만드는 다양한 다른 방법이 존재합니다. zeros()는 해당 배열에 모두 0을 삽입하고, ones()는 모두 1을 삽입합니다. full()은 배열에 사용자가 지정한 값을 넣는데 사용하고, eye()는 대각선으로는 1이고 나머지는 0인 2차원 배열을 생성합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkV_YM_mRh5p","executionInfo":{"status":"ok","timestamp":1637813423052,"user_tz":-540,"elapsed":450,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"9630b2d9-9428-4ea9-cb9b-fc1769e6b542"},"source":["a = np.zeros((2,3)) # 모든값이 0인 2x3 배열 생성.\n","print(a)"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0.]\n"," [0. 0. 0.]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXfEVy0eRh7p","executionInfo":{"status":"ok","timestamp":1637813892354,"user_tz":-540,"elapsed":512,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"1fbb1789-50f4-4224-a4d3-40fc56fae2a6"},"source":["a = np.ones((2,3))\n","print(a)\n","print(a.ndim)\n","print(a.shape)"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1. 1. 1.]\n"," [1. 1. 1.]]\n","2\n","(2, 3)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VP1JgNYsRh-T","executionInfo":{"status":"ok","timestamp":1637813909378,"user_tz":-540,"elapsed":4,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"241ac323-813a-4155-dd77-f981b3d49cbf"},"source":["a = np.full((2,2), 7) # 모든 값이 특정 상수인 배열 생성. 이 경우에는 7.\n","print(a)"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["[[7 7]\n"," [7 7]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dw2KE24HRiAw","executionInfo":{"status":"ok","timestamp":1637813924497,"user_tz":-540,"elapsed":512,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"229b52cf-a726-4e2e-b962-aca2930c7e0f"},"source":["# 대각 행렬\n","a = np.eye(3) # 대각선으로는 1이고 나머지는 0인 2차원 배열을 생성.\n","print(a) # 3,3 행렬"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BU48rF33RiC_","executionInfo":{"status":"ok","timestamp":1637813948374,"user_tz":-540,"elapsed":630,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"fb615425-0e72-4624-9e0f-1608b5956758"},"source":["a = np.random.random((2,2)) # 임의의 값으로 채워진 배열 생성\n","print(a)"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.47249823 0.08283439]\n"," [0.98983659 0.1526812 ]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZovEKy7_RiFo"},"source":["### np.arange()\n","- np.arange()는 지정해준 범위에 대해서 배열을 생성합니다. np.arange()의 범위 지정 방법은 다음과 같습니다.\n","\n","- numpy.arange(start, stop, step, dtype)\n","- a = np.arange(n) # 0, ..., n-1까지 범위의 지정.\n","- a = np.arange(i, j, k) # i부터 j-1까지 k씩 증가하는 배열."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBoXx8ftRiIO","executionInfo":{"status":"ok","timestamp":1637814321652,"user_tz":-540,"elapsed":552,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"ed1b9bcb-45e4-4a62-f63c-12241f58b10f"},"source":["a = np.arange(10)\n","print(a)\n","a = np.arange(1, 10, 2)\n","print(a)"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 3 4 5 6 7 8 9]\n","[1 3 5 7 9]\n"]}]},{"cell_type":"markdown","metadata":{"id":"RdfX032gRiKz"},"source":["### reshape() "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4dVRGtHRiNU","executionInfo":{"status":"ok","timestamp":1637814353691,"user_tz":-540,"elapsed":502,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"72cc9aa2-d7f0-4090-dbd1-ba5a5bf19b65"},"source":["a = np.array(np.arange(30)).reshape((5,6))\n","print(a)"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  1  2  3  4  5]\n"," [ 6  7  8  9 10 11]\n"," [12 13 14 15 16 17]\n"," [18 19 20 21 22 23]\n"," [24 25 26 27 28 29]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"m9Rk1MDFRiP9"},"source":["### Numpy 슬라이싱"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6BXS1jCRiSU","executionInfo":{"status":"ok","timestamp":1637814384799,"user_tz":-540,"elapsed":516,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"f371d7cc-dcf7-444c-cb03-18ef9e26d5af"},"source":["a = np.array([[1, 2, 3], [4, 5, 6]])\n","b = a[0:2, 0:2]\n","print(b)"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2]\n"," [4 5]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"aGHe3Yr2RiU9"},"source":["# 판다스 프로파일링"]},{"cell_type":"code","metadata":{"id":"CFS0IR72Ricx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sqtzTAJdRiis"},"source":["# 머신러닝 워크플로우"]},{"cell_type":"markdown","metadata":{"id":"jXvSulUnZbzo"},"source":["### 수집(Acquisition)\n","- 머신러닝을 하기 위해서는 기계에 학습시켜야 할 데이터가 필요하다. \n","- 자연어 데이터를 말뭉치 또는 코퍼스(corpus) 라고 부른다 \n","- 코퍼스의 뜻 조사나 연구 목적에 의해 특정 도메인으로부터 수집된 텍스트 집합 \n"]},{"cell_type":"markdown","metadata":{"id":"s3HfXB9nZ1oR"},"source":["### 점검 및 탐색 (Inspection and Exploration) \n","- 데이터의 구조 , 노이즈, 머신 러닝 적용을 위해 데이터를 어떻게 정제해야 하는지 등을 파악해야 한다. \n","- 탐색적 데이터 분석 (Exploatory Data Analysis, EDA) 단계 \n","- 독립 변수, 종속 변수, 변수 유형, 변수의 데이터 타입 등을 점검\n","- 데이터의 특징과 내재하는 구조적 관계를 알아내는 작업\n","- 시각화 및 간단한 통계 검정 "]},{"cell_type":"markdown","metadata":{"id":"ZzzbbEB4aid-"},"source":["### 전처리 및 정제(Preprocessing and Cleansing) \n","- 데이터에 대한 파악이 끝나면, 머신 러닝 워크플로우에서 가장 까다로운 작업 중 하나인 데이터 전처리 과정에 들어간다. \n","- 가령 자연어 처리라고 한다면, 토큰화, 정제, 정규화, 불용어 제거 등의 단계를 포함한다. 빠르고 정확한 데이터 전처리를 하기 위해서는 사용하고 있는 툴(파이썬)에 대한 다양한 라이브러리에 대한 지식이 필요하다. \n","- 정말 까다로운 전처리의 경우 전처리 과정에서 머신러닝이 사용되기도 한다"]},{"cell_type":"markdown","metadata":{"id":"cqJFH25GbLge"},"source":["### 모델링 및 훈련 (Modeling and Training)\n","- 데이터 전처리가 끝나면, 머신 러닝에 대한 코드를 작성하는 단계인 모델링 단계에 들어간다. \n","- 적절한 머신러닝 알고리즘들을 선택하여 모델링이 끝났다면, 전처리가 완료된 데이터를 머신 러닝 알고리즘을 통해 기계에서 학습(Training) 시킵니다. \n","- 훈련 이라고도 한다. \n","- 주의할점 : 대부분의 경우에서 모든 데이터를 기계에서 학습시켜서는 안된다는 점\n","- 데이터 중 일부는 테스트용으로 남겨두고 훈련용 데이터만 훈련에 사용해야 한다.\n","- 기계가 학습을 하고나서, 현재 성능이 얼마나 되는지를 측정할 수 있으며, 과적합(overfitting) 을 피할 수 있다. \n","- 데이터의 양이 충분하여 더 세부적으로 나눌 수 있다면 훈련용, 검증용, 테스트용 데이터로 나눈다. \n"]},{"cell_type":"markdown","metadata":{"id":"0gKdDjobcZdR"},"source":["### 평가(Evaluation) \n","- 기계가 다 학습되었다면 테스트용 데이터로 성능을 평가한다. 평가 방법은 기계가 예측한 데이터가 테스트용 데이터의 실제 정답과 얼마나 가까운지를 측정한다. "]},{"cell_type":"markdown","metadata":{"id":"Rwp1spQHcqLy"},"source":["### 배포(Deployment) \n","- 평가 단계에서 기계가 성공적으로 훈련이 된 것으로 판단되었다면, 완성된 모델이 배포되는 단계가 된다. "]},{"cell_type":"markdown","metadata":{"id":"BQDQTOKWc4JE"},"source":["# 텍스트 전처리 (Text Preprocessing)"]},{"cell_type":"markdown","metadata":{"id":"sQsDBcy0c8yL"},"source":["# 토큰화(Tokenization)\n","자연어 처리에서 크롤링 등으로 얻어낸 코퍼스 데이터가 필요에 맞게 전처리되지 않은 상태라면, 해당 데이터를 사용하고자하는 용도에 맞게 토큰화(tokenization) & 정제(cleaning) & 정규화(normalization)하는 일을 하게 됩니다. 이번 챕터에서는 그 중에서도 토큰화에 대해서 배우도록 합니다.\n","\n","주어진 코퍼스(corpus)에서 토큰(token)이라 불리는 단위로 나누는 작업을 토큰화(tokenization)라고 부릅니다. 토큰의 단위가 상황에 따라 다르지만, 보통 의미있는 단위로 토큰을 정의합니다."]},{"cell_type":"markdown","metadata":{"id":"vcDHfW_YdUcS"},"source":["### 단어 토큰화(Word Tokenization) \n","- 토큰의 기준을 단어(word)로 하는 경우, 단어 토큰화(word tokenization)라고 합니다. 다만, 여기서 단어(word)는 단어 단위 외에도 단어구, 의미를 갖는 문자열로도 간주되기도 합니다."]},{"cell_type":"markdown","metadata":{"id":"zgORrJVZdaHZ"},"source":["### 토큰화 중 생기는 선택의 순간\n","- 토큰화를 하다보면 예상하지 못한 경우가 있어서, 토큰화의 기준을 생각해봐야 하는 경우가 있다. 예를 들어 영어권 언어에서 아포스트로피(') 가 들어있는 단어는 어떻게 토큰화 해야 할까? \n","- 원하는 결과가 나오도록 토큰화 도구를 직접 설계할 수도 있겠지만, 기존에 공개된 도구들을 사용하였을 때의 결과가 사용자의 목적과 일치한다면 해당 도구를 사용할 수도 있을 것입니다. NLTK는 영어 코퍼스를 토큰화하기 위한 도구들을 제공합니다. 그 중 word_tokenize와 WordPunctTokenizer를 사용해서 NLTK에서는 아포스트로피를 어떻게 처리하는지 확인해보겠습니다.\n","\n"," "]},{"cell_type":"markdown","metadata":{"id":"7pYG9sUTe-nS"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpdRtZTgdwi4","executionInfo":{"status":"ok","timestamp":1637816583375,"user_tz":-540,"elapsed":1255,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"1bdc7868-fb74-4d91-9dfd-d543a4cb55c8"},"source":["import tokenize\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","print(word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"Q2TDxe95e74e"},"source":["- WordPunctTokenizer는 구두점을 별도로 분류하는 특징을 갖고 있기때문에, 앞서 확인했던 word_tokenize와는 달리 Don't를 Don과 '와 t로 분리하였으며, 이와 마찬가지로 Jone's를 Jone과 '와 s로 분리한 것을 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQNIKpEHeR76","executionInfo":{"status":"ok","timestamp":1637816665810,"user_tz":-540,"elapsed":600,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"aec61328-9841-4bca-d67d-c3e2b78c00ea"},"source":["from nltk.tokenize import WordPunctTokenizer  \n","print(WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"WPg-586Rev3j"},"source":["- 케라스 또한 토큰화 도구로서 text_to_word_sequence를 지원합니다. \n","- 케라스의 text_to_word_sequence는 기본적으로 모든 알파벳을 소문자로 바꾸면서 마침표나 컴마, 느낌표 등의 구두점을 제거합니다. 하지만 don't나 jone's와 같은 경우 아포스트로피는 보존하는 것을 볼 수 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wki0sSvOfHMM","executionInfo":{"status":"ok","timestamp":1637816780135,"user_tz":-540,"elapsed":14,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"c2aa6dcc-cd1b-478f-ff45-08b392d1a4cf"},"source":["from tensorflow.keras.preprocessing.text import text_to_word_sequence\n","print(text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"]}]},{"cell_type":"markdown","metadata":{"id":"wzqTnzn3fHtQ"},"source":["### 토큰화에서 고려해야 할 사항\n","- 토큰화 작업은 단순히 코퍼스에서 구두점을 제외하고 공백 기준으로 잘라내는 작업이라고 할 수 없다. \n","- 이러한 일은 보다 섬세한 알고리즘이 필요하다. \n","    - 1) 구두점이나 특수 문자를 단순 제외해서는 안된다. \n","    - 예를 들어 ) 마침표 (.) 와 같은 경우는 문장의 경계를 알 수 있는데 도움이 되므로 단어를 뽑아낼 때, 마침표를 제외하지 않을 수 있다. \n","    - 또 다른 예로는 단어 자체에 구두점이 포함되어 있을 수 있다. m.p.h 나 PH.D 와 같이 \n","    - 2) 줄임말과 단어 내에 띄어쓰기가 있는 경우\n","    - what're , we're , New York rock'n'roll "]},{"cell_type":"markdown","metadata":{"id":"HL4VTJrUfHv6"},"source":["### 표준토큰화 예제\n","- 표준으로 쓰이고 있는 토큰화 방법 중 하나인 Penn Treebank Tokenization\n","- 규칙 \n","- 규칙 1. 하이푼(-) 으로 구성된 단어는 하나로 유지한다.\n","- 규칙 2. doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkFSrg6kfHyN","executionInfo":{"status":"ok","timestamp":1637817377807,"user_tz":-540,"elapsed":603,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"cbd16893-4bc6-4154-aa81-213d5ff638fb"},"source":["from nltk.tokenize import TreebankWordTokenizer\n","tokenizer = TreebankWordTokenizer()\n","text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n","print(tokenizer.tokenize(text))"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"cjL_CQtKfH0o"},"source":["### 문장 토큰화 (Sentence Tokenization) \n","- 문장 분류 (Sentence Segmentation) \n","- "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENS8FUzhfH2v","executionInfo":{"status":"ok","timestamp":1637817667914,"user_tz":-540,"elapsed":520,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"89719083-60ff-47d2-aefe-6bee06568ef4"},"source":["from nltk.tokenize import sent_tokenize\n","text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n","print(sent_tokenize(text))"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"A7oHD1z2fH5H"},"source":["- 마침표가 문장 중간에 여러번 등장하는 경우\n","- NLTK는 단순히 마침표를 구분자로 하여 문장을 구분하지 않았기 때문에, Ph.D.를 문장 내의 단어로 인식하여 성공적으로 인식하는 것을 볼 수 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lHTqNX9vfH7V","executionInfo":{"status":"ok","timestamp":1637817761499,"user_tz":-540,"elapsed":618,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"d6d08f37-f487-4b74-af48-0fcf7b44248f"},"source":["text = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n","print(sent_tokenize(text))"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"p-uT9R1kfH9t"},"source":["### 한국어 문장 토큰화 패키지 kss"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqHBFedGfIAm","executionInfo":{"status":"ok","timestamp":1637817846288,"user_tz":-540,"elapsed":17300,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"48aaf059-4c42-4aae-dde5-09040ac35a83"},"source":["pip install kss"],"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kss\n","  Downloading kss-3.3.1.1.tar.gz (42.4 MB)\n","\u001b[K     |████████████████████████████████| 42.4 MB 1.7 MB/s \n","\u001b[?25hCollecting emoji\n","  Downloading emoji-1.6.1.tar.gz (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 40.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: kss, emoji\n","  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kss: filename=kss-3.3.1.1-py3-none-any.whl size=42449239 sha256=1265f1af5a087b1e371569473ab3d5888554278d89345c1c8574d37619f38436\n","  Stored in directory: /root/.cache/pip/wheels/6e/9d/1d/52871154eff5273abb86b96f4f984c1cd67c5bde64239b060a\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=1130de14a9324ebbcec154eca9236e3ed757680937a64dab78b60eea7bc883cc\n","  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n","Successfully built kss emoji\n","Installing collected packages: emoji, kss\n","Successfully installed emoji-1.6.1 kss-3.3.1.1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BFXn09ZjfIDD","executionInfo":{"status":"ok","timestamp":1637817866255,"user_tz":-540,"elapsed":9422,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"3c8db28c-3314-43cb-c5a4-0b6a580b8961"},"source":["import kss\n","text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n","print(kss.split_sentences(text))"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stderr","text":["[Korean Sentence Splitter]: Initializing Pynori...\n"]},{"output_type":"stream","name":"stdout","text":["['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"]}]},{"cell_type":"markdown","metadata":{"id":"RMLxkcE5fIFZ"},"source":["### 이진분류기(Binary Classifier)\n","- 문장 토큰화에서의 예외 사항을 발생시키는 마침표의 처리를 위해서 입력에 따라 두 개의 클래스로 분류하는 이진 분류기(binary classifier)를 사용하기도 합니다.\n","- 1. 마침표(.)가 단어의 일부분일 경우. 즉, 마침표가 약어(abbreivation)로 쓰이는 경우\n","- 2. 마침표(.)가 정말로 문장의 구분자(boundary)일 경우를 의미할 것입니다."]},{"cell_type":"markdown","metadata":{"id":"cwHGFIvdfIHr"},"source":["### 한국어에서의 토큰화의 어려움\n","- 영어는 New York 와 같은 합성어나 he's 와 같이 줄임말에 대한 예외처리만 한다면,\n","띄어쓰기(white space) 를 기준으로 하는 띄어쓰기 토큰화를 수행해도 단어 토큰화가 잘 작동한다. 거의 대부분의 경우에서 단어 단위로 띄어쓰기가 이루어지기 때문에 띄어쓰기 토큰화와 단어 토큰화가 거의 같다.\n","\n","- 하지만 한국어는 영어와는 달리 띄어쓰기만으로는 토큰화를 하기에 부족합니다. 한국어의 경우에는 띄어쓰기 단위가 되는 단위를 '어절'이라고 하는데 즉, 어절 토큰화는 한국어 NLP에서 지양되고 있습니다. 어절 토큰화와 단어 토큰화가 같지 않기 때문입니다. 그 근본적인 이유는 한국어가 영어와는 다른 형태를 가지는 언어인 교착어라는 점에서 기인합니다. 교착어란 조사, 어미 등을 붙여서 말을 만드는 언어를 말합니다."]},{"cell_type":"markdown","metadata":{"id":"yClcMiEUfIJ8"},"source":["### 한국어는 교착어다.\n","- 한국어에는 조사가 존재\n","- 즉, 띄어쓰기 단위가 영어처럼 독립적인 단어라면 띄어쓰기 단위로 토큰화를 하면 되겠지만 한국어는 어절이 독립적인 단어로 구성되는 것이 아니라 조사 등의 무언가가 붙어있는 경우가 많아서 이를 전부 분리해줘야 한다는 의미입니다.\n","- 형태소(morpheme)\n","- 형태소(morpheme)란 뜻을 가진 가장 작은 말의 단위를 말합니다.\n","- 자립 형태소 : 접사, 어미, 조사와 상관없이 자립하여 사용할 수 있는 형태소. 그 자체로 단어가 된다. 체언(명사, 대명사, 수사), 수식언(관형사, 부사), 감탄사 등이 있다.\n","- 의존 형태소 : 다른 형태소와 결합하여 사용되는 형태소. 접사, 어미, 조사, 어간를 말한다."]},{"cell_type":"markdown","metadata":{"id":"xKC022WEfIRI"},"source":["### 한국어는 띄어쓰기가 잘 지켜지지 않는다. \n","-  한국어의 경우 띄어쓰기가 지켜지지 않아도 글을 쉽게 이해할 수 있는 언어라는 점\n","- 한국어는 수많은 코퍼스에서 띄어쓰기가 무시되는 경우가 많아 자연어 처리가 어려워졌다는 것입니다."]},{"cell_type":"markdown","metadata":{"id":"kAYfflaafITn"},"source":["### 품사 태깅(part-of-speech tagging)\n","- 품사에 따라서 단어의 의미가 달라지기도 한다. \n","- fly : 동사 (날다) , 명사 (파리) \n","- 못 : 명사 와 부사로써의 의미가 다르다 \n","- 단어 토큰화 과정에서 각 단어가 어떤 품사로 쓰였는지를 구분해놓기도 하는데, 이 작업을 품사 태깅(part-of-speech tagging)이라고 합니다. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"viRCJEObfIWT","executionInfo":{"status":"ok","timestamp":1637818981518,"user_tz":-540,"elapsed":524,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"f74606f0-2d6e-4f4c-93b4-f49fad34e8fe"},"source":["from nltk.tokenize import word_tokenize\n","text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n","print(word_tokenize(text))"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n"]}]},{"cell_type":"markdown","metadata":{"id":"y8gk4_ycn6Hq"},"source":["- PRP는 인칭 대명사\n","- VBP는 동사\n","- RB는 부사\n","- VBG는 현재부사\n","- IN은 전치사\n","- NNP는 고유 명사\n","- NNS는 복수형 명사\n","- CC는 접속사\n","- DT는 관사"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUpNEy0EfIYo","executionInfo":{"status":"ok","timestamp":1637819038650,"user_tz":-540,"elapsed":7788,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"204f6b31-5c46-400d-e6b4-ff4a16389079"},"source":["nltk.download('averaged_perceptron_tagger')\n","from nltk.tag import pos_tag # 품사 태깅\n","tokenized_sentence = word_tokenize(text) # 단어 토큰화\n","print(pos_tag(tokenized_sentence)) "],"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"]}]},{"cell_type":"markdown","metadata":{"id":"-_UtvmMEnvP5"},"source":["- 한국어 자연어 처리를 위해서는 KoNLPy(\"코엔엘파이\"라고 읽습니다)라는 파이썬 패키지를 사용할 수 있습니다. 코엔엘파이를 통해서 사용할 수 있는 형태소 분석기로 Okt(Open Korea Text), 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma)가 있습니다.\n","- 한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소(morpheme) 단위로 형태소 토큰화(morpheme tokenization)를 수행하게 됨을 뜻합니다. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LpeIAHBUnzbk","executionInfo":{"status":"ok","timestamp":1637819215848,"user_tz":-540,"elapsed":26729,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"cea06009-fae7-4d0c-f560-5df92a2f6312"},"source":["# 형태소 토큰화\n","from konlpy.tag import Okt  \n","okt = Okt()  \n","print(okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"],"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDmmW8HvnzeX","executionInfo":{"status":"ok","timestamp":1637819281596,"user_tz":-540,"elapsed":451,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"32946b91-c7e0-46b9-d905-4929a7e3c57f"},"source":["# 품사 태깅\n","print(okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["[('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfB84dixnzg6","executionInfo":{"status":"ok","timestamp":1637819281597,"user_tz":-540,"elapsed":18,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"85677e14-496e-4074-8fda-c78a21225fc5"},"source":["# 명사 추출\n","print(okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"],"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["['코딩', '당신', '연휴', '여행']\n"]}]},{"cell_type":"markdown","metadata":{"id":"TRT61v-qnzjU"},"source":["- 형태소 추출과 품사 태깅 메소드의 결과를 보면, 조사를 기본적으로 분리하고 있음을 확인할 수 있습니다. 그렇기 때문에 한국어 NLP에서 전처리에 형태소 분석기를 사용하는 것은 꽤 유용합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUEkJxZRnzmc","executionInfo":{"status":"ok","timestamp":1637819405592,"user_tz":-540,"elapsed":25333,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"b9ec2b6a-b00d-4c52-bf1a-a4a486cf77bf"},"source":["from konlpy.tag import Kkma  \n","kkma = Kkma()  \n","print(kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"],"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJYs0RGqnzoU","executionInfo":{"status":"ok","timestamp":1637819405595,"user_tz":-540,"elapsed":22,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"328ed8f7-675d-4160-c0f0-797a321b7f02"},"source":["print(kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))  "],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["[('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3R8GeKjnzrZ","executionInfo":{"status":"ok","timestamp":1637819405594,"user_tz":-540,"elapsed":38,"user":{"displayName":"이용혁","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03778852977405454404"}},"outputId":"bcff3591-f378-4454-e42f-c739e13307d1"},"source":["print(kkma.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))  "],"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["['코딩', '당신', '연휴', '여행']\n"]}]},{"cell_type":"markdown","metadata":{"id":"WLOTYTx7nztq"},"source":["# 정제(Cleansing) 와 정규화(Normalization) \n","- 코퍼스에서 용도에 맞게 토큰을 분류하는 작업을 토큰화(tokenization)라고 하며, 토큰화 작업 전, 후에는 텍스트 데이터를 용도에 맞게 정제(cleaning) 및 정규화(normalization)하는 일이 항상 함께합니다."]},{"cell_type":"markdown","metadata":{"id":"DHajyDr8nzv_"},"source":["- 정제(cleaning) : 갖고 있는 코퍼스로부터 노이즈 데이터를 제거한다.\n","- 정규화(normalization) : 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어준다."]},{"cell_type":"markdown","metadata":{"id":"nd0Vgy3Bnzyt"},"source":["- 정제 작업은 토큰화 작업에 방해가 되는 부분들을 배제시키고 토큰화 작업을 수행하기 위해서 토큰화 작업보다 앞서 이루어지기도 하지만, 토큰화 작업 이후에도 여전히 남아있는 노이즈들을 제거하기위해 지속적으로 이루어지기도 합니다. 사실 완벽한 정제 작업은 어려운 편이라서, 대부분의 경우 이 정도면 됐다.라는 일종의 합의점을 찾기도 합니다."]},{"cell_type":"markdown","metadata":{"id":"uZqK3kjlnz1A"},"source":["- 1. 규칙에 기반한 표기가 다른 단어들의 통합\n","- 2. 대, 소문자 통합\n","- 3. 불필요한 단어의 제거(Removing Unnecessary Words)\n","    - (1) 등장 빈도가 적은 단어(Removing Rare words)\n","    - (2) 길이가 짧은 단어(Removing words with a very short length)\n","- 4. 정규 표현식(Regular Expression)\n"]},{"cell_type":"code","metadata":{"id":"3s4hOWwTnz3t"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFXWljA0nz5-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zAK2onjVnz8S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"944P4is0nz-G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQ8Ri9bfn0BH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uaMVBL-an0Dk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YuBN9Yr4n0GB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9_PRkc-Zn0Ip"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZX8CxBnn0LP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTU0LLaxn0Nl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4njT78Hvn0Pt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v05J0HCxn0Su"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VuMbax_qn0VA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kT6vaUXAn0X6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u4ThiiVan0cz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPTLuRVen0fa"},"source":[""],"execution_count":null,"outputs":[]}]}